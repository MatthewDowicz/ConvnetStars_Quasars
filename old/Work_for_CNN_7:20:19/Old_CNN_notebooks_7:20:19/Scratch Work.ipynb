{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quasar_z_range(redshift, sdss_id, noise):\n",
    "    \n",
    "    cut_redshifts = (redshift >= 1.8) & (redshift <= 2.2) # gives boolean list with T in the range 1.8-2.2\n",
    "    \n",
    "    filtered_ids = np.array(sdss_id)[np.array(cut_redshifts)] # gives the values in the ID array for the Ts in cut list\n",
    "    filtered_redshifts = np.array(redshift)[np.array(cut_redshifts)] # same as above but for the redshift array\n",
    "    filtered_noise = np.array(noise)[np.array(cut_redshifts)] # same as above but for the noise array\n",
    "    \n",
    "    cut_values = {\"ID\":filtered_ids, \"REDSHIFTS\":filtered_redshifts, \"NOISE\":filtered_noise} # puts these new lists\n",
    "                                                                                             # into a dictionary\n",
    "    \n",
    "    return cut_values\n",
    "\n",
    "cut_lists = quasar_z_range(redshift, sdss_id, noise)\n",
    "\n",
    "print(\"The SDSS ID's that are in the z range is \"  +str(cut_lists[\"ID\"]))\n",
    "print(\"The redshifts values that are in the z range is \"  +str(cut_lists[\"REDSHIFTS\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeresultsdict(resultsdict, outfileroot, outfileprefix=None):\n",
    "\n",
    "    mainoutfilename = outfileroot + '_donut_summary.txt'\n",
    "    with open(mainoutfilename, 'w') as fout:\n",
    "        donutsum = resultsdict['donut_summary']\n",
    "        for key in donutsum.keys():\n",
    "            outstr = key + ' ' + \"{:f}\".format(donutsum[key])+'\\n'\n",
    "            fout.write(outstr)\n",
    "    # now loop through and write out the results for each zernike\n",
    "    # write the numbers in one file, and the arrays one per file \n",
    "    for zdictname in ['z4ResultDict','z5ResultDict','z6ResultDict',\\\n",
    "                      'z7ResultDict','z8ResultDict']:\n",
    "        zdict = resultsdict[zdictname]\n",
    "        for zdictkey in ['thetax','thetaxErr','thetay','thetayErr',\\\n",
    "                         'delta','deltaErr','meanDeltaBefore',\\\n",
    "                         'rmsDeltaBefore','meanDeltaAfter',\\\n",
    "                         'rmsDeltaAfter']:\n",
    "            zoutfilename = outfileroot + '_' + zdictname + '.txt'\n",
    "            with open(zoutfilename, 'w') as fout:\n",
    "                outstr = zdictkey + ' ' + \"{:f}\".format(zdict[zdictkey])+'\\n'\n",
    "                fout.write(outstr)\n",
    "        for zarrayname in ['deltaArrayX','deltaArrayY',\\\n",
    "                           'deltaArrayBefore','deltaArrayAfter']:\n",
    "            zarray = zdict[zarrayname]\n",
    "            arroutname = outfileroot + '_' + zdictname + '_' + zarrayname + '.txt'\n",
    "            hdrstr = outfileroot + ' ' + zdictname + ' ' + zarrayname\n",
    "            np.savetxt(arroutname,zarray,header=hdrstr)\n",
    "# from Professor Rockosi's email from July 14, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quasar_z_range(redshifts, psfmag, plate, mjd, fiberid):\n",
    "    \n",
    "    fits_image_totalQ = fits.open(\"/Users/matt/Desktop/DESI_Research/DESI_ML/DR14_Q_spectra/DR14Q_v4_4.fits\")\n",
    "    hdul = fits_image_totalQ # this block of code is just reading in the data\n",
    "    quasar_data = hdul[\"DR14Q_v4_4\"].data\n",
    "    \n",
    "    redshift = quasar_data.field(str(redshifts)) # making the redshift vector\n",
    "    psfmagtable = quasar_data.field(str(str(psfmag))) # the light magnitudes are in a table\n",
    "    rmagvec = psfmagtable[:,2] # the r band is the 3 entry in the table, starts at 0 index\n",
    "    \n",
    "    plate = quasar_data.field(str(plate)) # making the plate vector\n",
    "    mjd = quasar_data.field(str(mjd)) # making the mjd vector\n",
    "    fiber = quasar_data.field(str(fiberid)) # making fiber vector\n",
    "    \n",
    "    cut_redshifts = (redshift >= 1.8) & (redshift <= 2.2) # gives boolean list with T in the range 1.8-2.2\n",
    "    cut_rband = rmagvec > 17. # the range we're looking for in r band\n",
    "    # ^ this range is opposite than what Professor Rockosi said, but it's the only way to get a sizable sample size\n",
    "    cutlist = (cut_rband) & (cut_redshifts) # ma\n",
    "    \n",
    "    filtered_plate = np.array(plate)[np.array(cutlist)] # gives the values in the ID array for the Ts in cut list\n",
    "    filtered_mjd = np.array(mjd)[np.array(cutlist)] # same as above but for the redshift array\n",
    "    filtered_fiberid = np.array(fiberid)[np.array(cutlist)] # same as above but for the noise array\n",
    "    \n",
    "    cut_values = {\"PLATE\":filtered_plate, \"MJD\":filtered_mjd, \"NOISE\":filtered_} # puts these new lists\n",
    "                                                                                             # into a dictionary\n",
    "    \n",
    "    return cut_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A quick example for using get_filenames. The idea is , it takes in a\n",
    "string as a path (read: folder), and returns all the names in the\n",
    "directory indicated by the path.\n",
    "\n",
    "Note that this assumes a Linux operating system, so smooth operation\n",
    "is not guaranteed in Mac.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "def get_filenames(path='.', extension=None, pattern=None, identifiers=None, include_path=False):\n",
    "    \"\"\"\n",
    "    Retrieves a list containing the filenames from a target directory.\n",
    "\n",
    "    By default this retrieves all entries in the directory, hereafter referred\n",
    "    to as filenames. Specific file types or folders can be retrieved by\n",
    "    filtering by extension, a portion of the filename, or a list of\n",
    "    identifiers. Also supports Regular Expression patterns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: string or path-like object, optional\n",
    "        The path from which to retrieve the filepaths. Default behavior is to\n",
    "        list the current directory.\n",
    "    extension: string, optional\n",
    "        The extension of the filenames to be retrieved. This works by comparing\n",
    "         the end of the entry names to the string specified, so it need not be\n",
    "        an extension, merely the end of entry-name you wish to retrieve.\n",
    "    pattern: string, optional\n",
    "        A pattern by which to filter what filenames and entries are returned. This\n",
    "        can be the whole filename, or just a portion. Alternately, a Regular\n",
    "        Expression can be provided. All entries that match in this fashion will be\n",
    "        returned.\n",
    "    identifiers: list or tuple, optional\n",
    "        Instead of a single string, a list of strings or numbers can be\n",
    "        provided. The list can contain whole filenames, or just portions of the\n",
    "        filenames. If a number is passed, the number is converted to a string.\n",
    "        This does not support Regular Expressions.\n",
    "    include_path: bool, optional\n",
    "        If True, the filenames are returned with the path appended to them.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    filename_list: a list of strings that contain the filenames after filtering\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    os.listdir: returns the names of all entries in a directory\n",
    "    re: module that supports regular expression matching operations for python\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    Retrieve a list of file names using a file extension, and a Regex pattern.\n",
    "\n",
    "    >>> biasframe_path = '/home/lee/Documents/bias_frames/'\n",
    "    >>> extension = '.fits.fz'\n",
    "    >>> pattern = '(?=.*k4m)'  # look-ahead regex pattern that checks for 'k4m'\n",
    "    >>> fits_list = get_filenames(biasframe_path, extension=extension, pattern=pattern)\n",
    "    >>> print(fits_list)\n",
    "    ['k4m_180211_231642_zri.fits.fz', 'k4m_180211_225927_zri.fits.fz', 'k4m_180211_231335_zri.fits.fz', 'k4m_180211_230119_zri.fits.fz', 'k4m_180211_231949_zri.fits.fz', 'k4m_180211_231834_zri.fits.fz', 'k4m_180211_231449_zri.fits.fz', 'k4m_180211_231604_zri.fits.fz', 'k4m_180211_231527_zri.fits.fz', 'k4m_180211_231911_zri.fits.fz', 'k4m_180211_230004_zri.fits.fz', 'k4m_180211_231719_zri.fits.fz', 'k4m_180211_231412_zri.fits.fz', 'k4m_180211_230042_zri.fits.fz', 'k4m_180211_231756_zri.fits.fz']\n",
    "\n",
    "    Retrieve a list of file names using a sequence of numbers\n",
    "\n",
    "    >>> identifiers = np.arange(190800, 190900)\n",
    "    >>> fits_list = get_filenames(biasframe_path, identifiers=identifiers)\n",
    "    >>> fits_list\n",
    "    ['c4d_170331_190830_zri.fits.fz', 'c4d_170331_190853_zri.fits.fz']\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    # retrieve all filenames from the directory\n",
    "    filename_list = os.listdir(path)\n",
    "\n",
    "    # keep all filenames with the proper extension\n",
    "    if extension is not None:\n",
    "        filename_list = [filename for filename in filename_list if\n",
    "                         filename[-len(extension):] == extension]\n",
    "\n",
    "    # keep all filenames that match the pattern\n",
    "    if pattern is not None:\n",
    "        filename_list = [filename for filename in filename_list if re.search(pattern, filename)]\n",
    "\n",
    "    # keep all filenames that match the identifiers provided\n",
    "    if identifiers is not None:\n",
    "        storage_list = []\n",
    "        try:\n",
    "            for ident in identifiers:\n",
    "                storage_list.extend([filename for filename in filename_list if str(ident) in filename])\n",
    "\n",
    "        except TypeError:\n",
    "            print(identifiers, 'is not a list, tuple, or otherwise iterable')\n",
    "        else:\n",
    "            filename_list = storage_list\n",
    "\n",
    "    if include_path:\n",
    "        filename_list = [path + filename for filename in filename_list]\n",
    "\n",
    "    return filename_list\n",
    "\n",
    "'''example code'''\n",
    "\n",
    "# outer path\n",
    "master_dir = '/home/lee/Data/darkcurrent_25c/'\n",
    "# retrieve the list of directories that contain exposures.\n",
    "# conveniently, I have ended the name of everything that\n",
    "# has what I want with 'exposure', so I can take advantage\n",
    "# of how the extension variable looks at the end of the name\n",
    "sub_dir_list = get_filenames(master_dir, extension='exposure')\n",
    "print(sub_dir_list) # print to check the output\n",
    "'''\n",
    ">>> print(sub_dir_list) # print to check the output\n",
    "['60s_exposure', '30s_exposure', '240s_exposure', '15s_exposure', '120s_exposure']\n",
    "'''\n",
    "\n",
    "# this makes a list of lists, with each entry in the outer list corresponding to a\n",
    "# subdirectory, and each inner list being the file names withing that subdirectory\n",
    "sub_dir_filenames = []\n",
    "for sub_dir in sub_dir_list:\n",
    "    path = master_dir + sub_dir + '/'  # adding a slash, to account for how os.listdir(path) does not include one\n",
    "    # retrieve the filenames, checking the extension to make sure\n",
    "    # this time, include path is turned on, so the entire directory pointing to the file will be included\n",
    "    sub_dir_filenames.append(get_filenames(path, extension='.fits', include_path=True))\n",
    "\n",
    "# print to check the output\n",
    "for filename_list in sub_dir_filenames: print(filename_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datafrommultiplefolders(foldername,start,end):\n",
    "    # create an empty listt\n",
    "    sub_dir_list_fin = []\n",
    "\n",
    "    # goes through all the folders with their names in the start and end of the range. Slight modification\n",
    "    # to Lee's code.\n",
    "    for i in range(start,end):\n",
    "        try:\n",
    "            master_dir = \"/Users/matt/Desktop/DESI_Research/DESI_ML/\"+str(foldername)+'/' + str(i)\n",
    "            sub_dir_list_fin.append(get_filenames(path = master_dir, extension = '.fits')) \n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # this flatttens the list. This is b/c w/o doing this you have a list of lists\n",
    "    flat_list = [item for sublist in sub_dir_list_fin for item in sublist]\n",
    "\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code copies the fits in their respective folders into one folder\n",
    "\n",
    "def copyfiles_fromfolder_tofolder(Root_dir,target_folder,extension)\n",
    "    RootDir1 = str(Root_dir)\n",
    "    TargetFolder = str(target_folder)\n",
    "    for root, dirs, files in os.walk((os.path.normpath(RootDir1)), topdown=False):\n",
    "        for name in files:\n",
    "            if name.endswith(str(extension)):\n",
    "                SourceFolder = os.path.join(root,name)\n",
    "                shutil.copy2(SourceFolder, TargetFolder)\n",
    "\n",
    "\n",
    "# this is the function code w/ example\n",
    "\n",
    "RootDir1 = \"/Users/matt/Desktop/DESI_Research/DESI_ML/Valid_Quasar_Data\"\n",
    "TargetFolder = \"/Users/matt/Desktop/DESI_Research/DESI_ML/good_quasars\"\n",
    "for root, dirs, files in os.walk((os.path.normpath(RootDir1)), topdown=False):\n",
    "        for name in files:\n",
    "            if name.endswith('.fits'):\n",
    "                #print(\"Found\")\n",
    "                SourceFolder = os.path.join(root,name)\n",
    "                shutil.copy2(SourceFolder, TargetFolder) #copies csv to new folder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitsfromfolders(foldername,start,end):\n",
    "    sub_dir_list_fin = []\n",
    "    for i in range(start,end):\n",
    "        try:\n",
    "            master_dir = \"/Users/matt/Desktop/DESI_Research/DESI_ML/\"+str(foldername)+'/' + str(i)\n",
    "            sub_dir_list_fin.append(get_filenames(path = master_dir, extension = '.fits')) \n",
    "        except:\n",
    "            pass\n",
    "    flat_list = [item for sublist in sub_dir_list_fin for item in sublist]\n",
    "    \n",
    "    \n",
    "    return flat_list\n",
    "\n",
    "'''\n",
    "vfits_listD15 = fitsfromfolders(\"Valid_Quasar_Data\", 3585, 10001)\n",
    "print(len(vfits_listD15))\n",
    "nvfits_listD15 = fitsfromfolders(\"DR15_wrong_rband_Quasars\", 3585, 10001)\n",
    "print(len(nvfits_listD15))\n",
    "nvfits_listD14 = fitsfromfolders(\"DR14_wrong_rband\", 3585, 10001)\n",
    "print(len(nvfits_listD15))\n",
    "\n",
    "reading_in(\"DR15_wrong_rband_Quasars\", nvfits_listD15, 3585, 10001)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quasardata = get_filenames(\"/Users/matt/Desktop/DESI_Research/DESI_ML/good_quasars/\", extension='.fits')\n",
    "batched_quasardata = np.array_split(np.array(quasardata),9)\n",
    "\n",
    "%%time \n",
    "\n",
    "noise = []\n",
    "for i in range(len(quasardata)):\n",
    "    with fits.open(\"/Users/matt/Desktop/DESI_Research/DESI_ML/good_quasars/\" +str(quasardata[i])+ \"\") as hdul:\n",
    "        data = hdul['SPALL'].data\n",
    "        SN = data.field(\"SN_MEDIAN_ALL\")\n",
    "        noise.extend(SN)  #np.extend just adds another item to the list\n",
    "        hdul.close()\n",
    "        del hdul['SPALL'].data\n",
    "        del hdul['COADD'].data\n",
    "        del hdul['PRIMARY'].data \n",
    "        del hdul\n",
    "#     hdul.close()\n",
    "\n",
    "print(len(noise))\n",
    "\n",
    "'''\n",
    "7974\n",
    "CPU times: user 14min 16s, sys: 12 s, total: 14min 28s\n",
    "Wall time: 15min 27s\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quasardata = get_filenames(\"/Users/matt/Desktop/DESI_Research/DESI_ML/good_quasars/\", extension='.fits')\n",
    "batched_quasardata = np.array_split(np.array(quasardata),9)\n",
    "\n",
    "%%time\n",
    "\n",
    "noise = []\n",
    "for i in range(len(batched_quasardata)):\n",
    "    for j in range(len(batched_quasardata[0])):\n",
    "        with fits.open(\"/Users/matt/Desktop/DESI_Research/DESI_ML/good_quasars/\" +str(batched_quasardata[i][j])+ \"\") as hdul:\n",
    "            data = hdul['SPALL'].data\n",
    "            SN = data.field(\"SN_MEDIAN_ALL\")\n",
    "            noise.extend(SN)  #np.extend just adds another item to the list\n",
    "            hdul.close()\n",
    "            del hdul['SPALL'].data\n",
    "            del hdul['COADD'].data\n",
    "            del hdul['PRIMARY'].data   \n",
    "            del hdul\n",
    "#     hdul.close()\n",
    "\n",
    "print(len(noise))\n",
    "\n",
    "'''\n",
    "7974\n",
    "CPU times: user 14min 49s, sys: 11 s, total: 15min\n",
    "Wall time: 15min 46s\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quasardata = get_filenames(\"/Users/matt/Desktop/DESI_Research/DESI_ML/good_quasars/\", extension='.fits')\n",
    "batched_quasardata = np.array_split(np.array(quasardata),9)\n",
    "\n",
    "%%time \n",
    "\n",
    "noise = []\n",
    "for i in range(len(quasardata)):\n",
    "    with fits.open(\"/Users/matt/Desktop/DESI_Research/DESI_ML/good_quasars/\" +str(quasardata[i])+ \"\") as hdul:\n",
    "        data = hdul['SPALL'].data\n",
    "        SN = data.field(\"SN_MEDIAN_ALL\")\n",
    "        noise.extend(SN)  #np.extend just adds another item to the list\n",
    "        hdul.close()\n",
    "        #del hdul['SPALL'].data\n",
    "        #del hdul['COADD'].data\n",
    "        #del hdul['PRIMARY'].data \n",
    "        del hdul\n",
    "#     hdul.close()\n",
    "\n",
    "print(len(noise))\n",
    "\n",
    "'''\n",
    "7974\n",
    "CPU times: user 15min 48s, sys: 25.6 s, total: 16min 13s\n",
    "Wall time: 17min 34s\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_filenames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-82fb2994b130>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquasardata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_filenames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/matt/Desktop/DESI_Research/DESI_ML/good_quasars/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.fits'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbatched_quasardata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquasardata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_filenames' is not defined"
     ]
    }
   ],
   "source": [
    "quasardata = get_filenames(\"/Users/matt/Desktop/DESI_Research/DESI_ML/good_quasars/\", extension='.fits')\n",
    "batched_quasardata = np.array_split(np.array(quasardata),9)\n",
    "\n",
    "%%time\n",
    "\n",
    "noise = []\n",
    "for i in range(len(batched_quasardata)):\n",
    "    for j in range(len(batched_quasardata[0])):\n",
    "        with fits.open(\"/Users/matt/Desktop/DESI_Research/DESI_ML/good_quasars/\" +str(batched_quasardata[i][j])+ \"\") as hdul:\n",
    "            data = hdul['SPALL'].data\n",
    "            SN = data.field(\"SN_MEDIAN_ALL\")\n",
    "            noise.extend(SN)  #np.extend just adds another item to the list\n",
    "            del hdul\n",
    "            \n",
    "#             del hdul['SPALL'].data\n",
    "#             del hdul['COADD'].data\n",
    "#             del hdul['PRIMARY'].data   \n",
    "#     hdul.close()\n",
    "\n",
    "print(len(noise))\n",
    "\n",
    "'''\n",
    "7974\n",
    "CPU times: user 13min 41s, sys: 9.87 s, total: 13min 51s\n",
    "Wall time: 15min 38s\n",
    "18\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quasardata = get_filenames(\"/Users/matt/Desktop/DESI_Research/DESI_ML/good_quasars/\", extension='.fits')\n",
    "batched_quasardata = np.array_split(np.array(quasardata),18)\n",
    "\n",
    "%%time\n",
    "\n",
    "noise = []\n",
    "for i in range(len(batched_quasardata)):\n",
    "    for j in range(len(batched_quasardata[0])):\n",
    "        with fits.open(\"/Users/matt/Desktop/DESI_Research/DESI_ML/good_quasars/\" +str(batched_quasardata[i][j])+ \"\") as hdul:\n",
    "            data = hdul['SPALL'].data\n",
    "            SN = data.field(\"SN_MEDIAN_ALL\")\n",
    "            noise.extend(SN)  #np.extend just adds another item to the list\n",
    "            hdul.close()\n",
    "            del hdul['SPALL'].data\n",
    "            del hdul['COADD'].data\n",
    "            del hdul['PRIMARY'].data   \n",
    "#     hdul.close()\n",
    "\n",
    "print(len(noise))\n",
    "\n",
    "'''\n",
    "7974\n",
    "CPU times: user 14min 35s, sys: 12.5 s, total: 14min 47s\n",
    "Wall time: 15min 29s\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_filenames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-06ba0b1c4ba0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquasardata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_filenames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/matt/Desktop/DESI_Research/DESI_ML/good_quasars/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.fits'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbatched_quasardata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquasardata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_filenames' is not defined"
     ]
    }
   ],
   "source": [
    "quasardata = get_filenames(\"/Users/matt/Desktop/DESI_Research/DESI_ML/good_quasars/\", extension='.fits')\n",
    "batched_quasardata = np.array_split(np.array(quasardata),9)\n",
    "\n",
    "%%time\n",
    "\n",
    "noise = []\n",
    "#flux = []\n",
    "for i in range(len(batched_quasardata)):\n",
    "    for j in range(len(batched_quasardata[0])):\n",
    "        with fits.open(\"/Users/matt/Desktop/DESI_Research/DESI_ML/good_quasars/\" +str(batched_quasardata[i][j])+ \"\", memmap = False) as hdul:\n",
    "            data = hdul['SPALL'].data\n",
    "            SN = data.field(\"SN_MEDIAN_ALL\")\n",
    "            noise.extend(SN)  #np.extend just adds another item to the list\n",
    "            hdul.close()\n",
    "            del hdul['SPALL'].data\n",
    "            del hdul['COADD'].data\n",
    "            del hdul['PRIMARY'].data   \n",
    "#     hdul.close()\n",
    "\n",
    "print(len(noise))\n",
    "\n",
    "#this is the fastest for loop to obtain the noise data for the quasar spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(noise, bins= range(0,50), histtype = 'bar' )\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Magnitude of S/N')\n",
    "plt.title(\"Histogram of Noise of ~7000 Quasar Spectra\")\n",
    "plt.axvline(np.mean(noise), color='k', linestyle='dashed', linewidth=1, label = 'Mean')\n",
    "plt.legend()\n",
    "print('Noise mean = ', np.mean(noise))\n",
    "\n",
    "# histograms of the noise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filevalues(filename_list): \n",
    "    \n",
    "    list_fluxarrays = []\n",
    "    list_objtype = []\n",
    "    list_noise = []\n",
    "    list_wavelength = []\n",
    "    list_redshift = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(len(stardata)):\n",
    "        with fits.open(\"/Users/matt/Desktop/DESI_Research/DESI_ML/good_stars/\" +str(stardata[i])+ \"\",\\\n",
    "                       memmap = False ) as hdul:\n",
    "            \n",
    "            data_c = hdul['COADD'].data\n",
    "            data_s = hdul['SPALL'].data\n",
    "            \n",
    "            flux_val = data_c.field(\"flux\")\n",
    "            list_fluxarrays.append(flux_val) \n",
    "            \n",
    "            objtype = data_s.field('OBJTYPE')\n",
    "            list_objtype.append(objtype)\n",
    "            \n",
    "            noise_val = data_s.field('SN_MEDIAN_ALL')\n",
    "            list_noise.append(noise_val)\n",
    "            \n",
    "            wavelength_val = data_c.field('loglam')\n",
    "            list_wavelength.append(wavelength_val)\n",
    "            \n",
    "            redshift_val = data_s.field('Z')\n",
    "            list_redshift.append(redshift_val)\n",
    "            \n",
    "            values = {'FLUX': list_fluxarrays, 'OBJTYPE': list_objtype, 'NOISE': list_noise,\\\n",
    "                      'WAVE': list_wavelength, 'REDSHIFT': list_redshift}\n",
    "            \n",
    "            hdul.close()\n",
    "            del hdul['COADD'].data\n",
    "            del hdul['PRIMARY'].data\n",
    "            del hdul['SPALL'].data\n",
    "            del hdul\n",
    "            \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = plt.hist(fluxlen_list, bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Used in Quasar_data_inrange.ipynb\n",
    "\"\"\"\n",
    "\n",
    "# processes the flux data so it's averaged between 0 & 1\n",
    "def preprocessing_data(values_dict): \n",
    "    \n",
    "    maxlist = []\n",
    "    filtered_flux_list = []\n",
    "    for i in range(len(values_dict['FLUX'])):\n",
    "        maxlist.append(max(values_dict['FLUX'][i]))\n",
    "        \n",
    "    maxval = max(maxlist)  # go back and fix this. The lists have to sum to 1\n",
    "    \n",
    "    for i in range(len(values_dict['FLUX'])):\n",
    "        filtered_flux_list.append((values_dict['FLUX'][i])/maxval)\n",
    "       \n",
    "    return filtered_flux_list\n",
    "\n",
    "# gives me the average length of all the flux arrays\n",
    "def meanlength_flux_arrays(filtered_flux_list): \n",
    "    \n",
    "    length = []\n",
    "    for i in range(len(filtered_flux_arrays)):\n",
    "        \n",
    "        length.append(len(filtered_flux_arrays[i]))\n",
    "        mean_length = np.mean(length)\n",
    "        \n",
    "    return mean_length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "pdb.pm()\n",
    "\n",
    "# SUPER AMAZING. DEBUGGER!!! PYTHON DEBUGGER. pm stand for postmortem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
