{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import keras\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import pdb\n",
    "#sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_in_data(filename):\n",
    "    \n",
    "    filename = str(filename)\n",
    "\n",
    "    infile = open(filename,'rb')\n",
    "    new_dict = pickle.load(infile)\n",
    "    infile.close()\n",
    "    \n",
    "    return new_dict        \n",
    "\n",
    "\n",
    "\n",
    "def sifting_data_dicts(data_dict, min_cut, max_cut):\n",
    "    \n",
    "    high_SN_dict = data_dict['HIGH']\n",
    "    mid_SN_dict = data_dict['MID']\n",
    "    low_SN_dict = data_dict['LOW']\n",
    "    \n",
    "    # initial flux, label, wavelength, redshift, and noise for the different SN range data sets\n",
    "    init_high_SN_flux = high_SN_dict['FLUX']\n",
    "    init_high_SN_labels = high_SN_dict['CLASS']\n",
    "    init_high_SN_wave = high_SN_dict['WAVE']\n",
    "    init_high_SN_redshift = high_SN_dict['REDSHIFT']\n",
    "    init_high_SN_noise = high_SN_dict['NOISE']\n",
    "    \n",
    "    init_mid_SN_flux = mid_SN_dict['FLUX']\n",
    "    init_mid_SN_labels = mid_SN_dict['CLASS']\n",
    "    init_mid_SN_wave = mid_SN_dict['WAVE']\n",
    "    init_mid_SN_redshift = mid_SN_dict['REDSHIFT']\n",
    "    init_mid_SN_noise = mid_SN_dict['NOISE']\n",
    "    \n",
    "    init_low_SN_flux = low_SN_dict['FLUX']\n",
    "    init_low_SN_labels = low_SN_dict['CLASS']\n",
    "    init_low_SN_wave = low_SN_dict['WAVE']\n",
    "    init_low_SN_redshift = low_SN_dict['REDSHIFT']\n",
    "    init_low_SN_noise = low_SN_dict['NOISE']\n",
    "    \n",
    "    \n",
    "# empty lists to store the flux,labels, wavelength, redshift, and noise for the different SN ranged datasets\n",
    "    high_SN_labels = []\n",
    "    high_SN_flux = []\n",
    "    high_SN_wave = []\n",
    "    high_SN_redshift = []\n",
    "    high_SN_noise = []\n",
    "    \n",
    "    mid_SN_labels = []\n",
    "    mid_SN_flux = []\n",
    "    mid_SN_wave = []\n",
    "    mid_SN_redshift = []\n",
    "    mid_SN_noise = []\n",
    "    \n",
    "    low_SN_labels = []\n",
    "    low_SN_flux = []\n",
    "    low_SN_wave = []\n",
    "    low_SN_redshift = []\n",
    "    low_SN_noise = []\n",
    "    \n",
    "\n",
    "# Making sure that there are only stars and quasars in the data set and making sure that every object has \n",
    "# spectra within the range we assigned to allow for a homogenous dataset for the CNN to see\n",
    "\n",
    "    # selection for high SN data\n",
    "    for i in range(len(init_high_SN_labels)):\n",
    "        \n",
    "        if (init_high_SN_labels[i] == 'QSO') & (min(init_high_SN_wave[i]) <= min_cut) &\\\n",
    "        (max(init_high_SN_wave[i]) >= max_cut):\n",
    "            \n",
    "            high_SN_labels.append(init_high_SN_labels)\n",
    "            high_SN_flux.append(init_high_SN_flux)\n",
    "            high_SN_wave.append(init_high_SN_wave)\n",
    "            high_SN_redshift.append(init_high_SN_redshift)\n",
    "            high_SN_noise.append(init_high_SN_noise)\n",
    "        \n",
    "        \n",
    "        elif (init_high_SN_labels[i] == 'STAR') & (min(init_high_SN_wave[i]) <= min_cut) &\\\n",
    "        (max(init_high_SN_wave[i]) >= max_cut):\n",
    "            \n",
    "            high_SN_labels.append(init_high_SN_labels)\n",
    "            high_SN_flux.append(init_high_SN_flux)\n",
    "            high_SN_wave.append(init_high_SN_wave)\n",
    "            high_SN_redshift.append(init_high_SN_redshift)\n",
    "            high_SN_noise.append(init_high_SN_noise)\n",
    "        \n",
    "        else: \n",
    "            pass\n",
    "        \n",
    "        \n",
    "        \n",
    "    # selection for mid range SN data\n",
    "    for i in range(len(init_mid_SN_labels)):\n",
    "        \n",
    "        if (init_mid_SN_labels[i] == 'QSO') & (min(init_mid_SN_wave[i]) <= min_cut) &\\\n",
    "        (max(init_mid_SN_wave[i]) >= max_cut):\n",
    "            \n",
    "            mid_SN_labels.append(init_mid_SN_labels)\n",
    "            mid_SN_flux.append(init_mid_SN_flux)\n",
    "            mid_SN_wave.append(init_mid_SN_wave)\n",
    "            mid_SN_redshift.append(init_mid_SN_redshift)\n",
    "            mid_SN_noise.append(init_mid_SN_noise)\n",
    "            \n",
    "            \n",
    "            \n",
    "        elif (init_mid_SN_labels[i] == 'STAR') & (min(init_mid_SN_wave[i]) <= min_cut) &\\\n",
    "        (max(init_mid_SN_wave[i]) >= max_cut):\n",
    "            \n",
    "            mid_SN_labels.append(init_mid_SN_labels)\n",
    "            mid_SN_flux.append(init_mid_SN_flux)\n",
    "            mid_SN_wave.append(init_mid_SN_wave)\n",
    "            mid_SN_redshift.append(init_mid_SN_redshift)\n",
    "            mid_SN_noise.append(init_mid_SN_noise)\n",
    "        \n",
    "        else: \n",
    "            pass\n",
    "        \n",
    "        \n",
    "    # selection for low SN data\n",
    "    for i in range(len(init_low_SN_labels)):\n",
    "        \n",
    "        if (init_low_SN_labels[i] == 'QSO') & (min(init_low_SN_wave[i]) <= min_cut) &\\\n",
    "        (max(init_low_SN_wave[i]) >= max_cut):\n",
    "            \n",
    "            low_SN_labels.append(init_low_SN_labels)\n",
    "            low_SN_flux.append(init_low_SN_flux)\n",
    "            low_SN_wave.append(init_low_SN_wave)\n",
    "            low_SN_redshift.append(init_low_SN_redshift)\n",
    "            low_SN_noise.append(init_low_SN_noise)\n",
    "            \n",
    "            \n",
    "        elif (init_low_SN_labels[i] == 'STAR') & (min(init_low_SN_wave[i]) <= min_cut) &\\\n",
    "        (max(init_low_SN_wave[i]) >= max_cut):\n",
    "            \n",
    "            low_SN_labels.append(init_low_SN_labels)\n",
    "            low_SN_flux.append(init_low_SN_flux)\n",
    "            low_SN_wave.append(init_low_SN_wave)\n",
    "            low_SN_redshift.append(init_low_SN_redshift)\n",
    "            low_SN_noise.append(init_low_SN_noise)\n",
    "        \n",
    "        else: \n",
    "            pass\n",
    "        \n",
    "        \n",
    "    # high SN dict   \n",
    "    high_SN_dict = {'LABELS': high_SN_labels, 'FLUX': high_SN_flux, 'WAVE': high_SN_wave,\\\n",
    "                    'REDSHIFT': high_SN_redshift, 'NOISE': high_SN_noise}\n",
    "    \n",
    "    # mid range SN dict\n",
    "    mid_SN_dict = {'LABELS': mid_SN_labels, 'FLUX': mid_SN_flux, 'WAVE': mid_SN_wave,\\\n",
    "                    'REDSHIFT': mid_SN_redshift, 'NOISE': mid_SN_noise}\n",
    "    \n",
    "    # low SN dict\n",
    "    low_SN_dict = {'LABELS': low_SN_labels, 'FLUX': low_SN_flux, 'WAVE': low_SN_wave,\\\n",
    "                    'REDSHIFT': low_SN_redshift, 'NOISE': low_SN_noise}\n",
    "            \n",
    "    \n",
    "    # dict holding the other dicts\n",
    "    SN_dict = {'HIGH': high_SN_dict, 'MID': mid_SN_dict, 'LOW': low_SN_dict}\n",
    "    \n",
    "    return SN_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def labeling_data(data_dict):        \n",
    "    \n",
    "    high_SN_dict = data_dict['HIGH']\n",
    "    mid_SN_dict = data_dict['MID']\n",
    "    low_SN_dict = data_dict['LOW']\n",
    "    \n",
    "    \n",
    "    high_SN_flux = high_SN_dict['FLUX']\n",
    "    high_SN_labels = high_SN_dict['LABELS']\n",
    "    high_SN_wave = high_SN_dict['WAVE']\n",
    "    high_SN_noise = high_SN_dict['NOISE']\n",
    "    high_SN_redshift = high_SN_dict['REDSHIFT']\n",
    "    \n",
    "    mid_SN_flux = mid_SN_dict['FLUX']\n",
    "    mid_SN_labels = mid_SN_dict['LABELS']\n",
    "    mid_SN_wave = mid_SN_dict['WAVE']\n",
    "    mid_SN_noise = mid_SN_dict['NOISE']\n",
    "    mid_SN_redshift = mid_SN_dict['REDSHIFT']\n",
    "    \n",
    "    low_SN_flux = low_SN_dict['FLUX']\n",
    "    low_SN_labels = low_SN_dict['LABELS']\n",
    "    low_SN_wave = low_SN_dict['WAVE']\n",
    "    low_SN_noise = low_SN_dict['NOISE']\n",
    "    low_SN_redshift = low_SN_dict['REDSHIFT']\n",
    "    \n",
    "\n",
    "    \n",
    "    for i in range(len(high_SN_labels)):\n",
    "        \n",
    "        if high_SN_labels[i][i] == \"QSO\":\n",
    "            high_SN_labels[i][i] = 1\n",
    "\n",
    "            \n",
    "        elif high_SN_labels[i][i] == 'STAR':\n",
    "            high_SN_labels[i][i] = 0\n",
    "        \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    for i in range(len(mid_SN_labels)):\n",
    "        \n",
    "        if mid_SN_labels[i][i] == \"QSO\":\n",
    "            mid_SN_labels[i][i] = 1\n",
    "            \n",
    "        elif mid_SN_labels[i][i] == \"STAR\":\n",
    "            mid_SN_labels[i][i] = 0\n",
    "        \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    for i in range(len(low_SN_labels)):\n",
    "        \n",
    "        if low_SN_labels[i][i] == \"QSO\":\n",
    "            low_SN_labels[i][i] = 1\n",
    "            \n",
    "        elif low_SN_labels[i][i] == \"STAR\":\n",
    "            low_SN_labels[i][i] = 0\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    high_SN_dict = {'FLUX': high_SN_flux, 'WAVE': high_SN_wave, 'NOISE': high_SN_noise,\\\n",
    "                   'REDSHIFT': high_SN_redshift, 'LABELS': high_SN_labels}\n",
    "    \n",
    "    mid_SN_dict = {'FLUX': mid_SN_flux, 'WAVE': mid_SN_wave, 'NOISE': mid_SN_noise,\\\n",
    "                   'REDSHIFT': mid_SN_redshift, 'LABELS': mid_SN_labels}\n",
    "    \n",
    "    low_SN_dict = {'FLUX': low_SN_flux, 'WAVE': low_SN_wave, 'NOISE': low_SN_noise,\\\n",
    "                   'REDSHIFT': low_SN_redshift, 'LABELS': low_SN_labels}\n",
    "    \n",
    "    \n",
    "    SN_dict = {'HIGH': high_SN_dict, 'MID': mid_SN_dict, 'LOW': low_SN_dict}\n",
    "\n",
    "    \n",
    "    return SN_dict\n",
    "   # return high_SN_labels\n",
    "        \n",
    "\n",
    "\n",
    "def randomizing_data(data_dict):\n",
    "    \n",
    "    high_SN_dict = data_dict['HIGH']\n",
    "    mid_SN_dict = data_dict['MID']\n",
    "    low_SN_dict = data_dict['LOW']\n",
    "    \n",
    "    \n",
    "    high_SN_flux = high_SN_dict['FLUX']\n",
    "    high_SN_labels = high_SN_dict['LABELS']\n",
    "    high_SN_wave = high_SN_dict['WAVE']\n",
    "    high_SN_noise = high_SN_dict['NOISE']\n",
    "    high_SN_redshift = high_SN_dict['REDSHIFT']\n",
    "    \n",
    "    mid_SN_flux = mid_SN_dict['FLUX']\n",
    "    mid_SN_labels = mid_SN_dict['LABELS']\n",
    "    mid_SN_wave = mid_SN_dict['WAVE']\n",
    "    mid_SN_noise = mid_SN_dict['NOISE']\n",
    "    mid_SN_redshift = mid_SN_dict['REDSHIFT']\n",
    "    \n",
    "    low_SN_flux = low_SN_dict['FLUX']\n",
    "    low_SN_labels = low_SN_dict['LABELS']\n",
    "    low_SN_wave = low_SN_dict['WAVE']\n",
    "    low_SN_noise = low_SN_dict['NOISE']\n",
    "    low_SN_redshift = low_SN_dict['REDSHIFT']\n",
    "                     \n",
    "                     \n",
    "    \n",
    "\n",
    "    star_labels = np.ones(len(star_labels))\n",
    "    quasar_labels = np.zeros(len(quasar_labels))\n",
    "    \n",
    "    input_flux = star_flux + quasar_flux\n",
    "    input_flux = np.asarray(input_flux)\n",
    "    \n",
    "    input_labels = np.concatenate((star_labels,quasar_labels), axis = 0)\n",
    "    \n",
    "    input_wave = star_wave + quasar_wave\n",
    "    input_wave = np.asarray(input_wave)\n",
    "    \n",
    "    input_noise = star_noise + quasar_noise\n",
    "    input_noise = np.asarray(input_noise)\n",
    "    \n",
    "    input_redshift = star_redshift+ quasar_redshift\n",
    "    input_redshift = np.asarray(input_redshift)\n",
    "    \n",
    "    permutation = np.random.permutation(len(input_flux)) # creates the same permutation to be done on flux & labels\n",
    "    \n",
    "    # needs to be array to permute for classification\n",
    "    randomized_flux = input_flux[permutation] \n",
    "    randomized_labels = input_labels[permutation]\n",
    "    randomized_wave = input_wave[permutation]\n",
    "    randomized_noise = input_noise[permutation]\n",
    "    randomized_redshift = input_redshift[permutation]\n",
    "\n",
    "    randomized_flux = randomized_flux.tolist() # needs to be a list to be used in creating tensor function\n",
    "    \n",
    "    randomized_data = {'FLUX': randomized_flux, 'LABELS': randomized_labels, 'WAVE': randomized_wave,\\\n",
    "                      'NOISE': randomized_noise, 'REDSHIFT': randomized_redshift, 'PERMUTATION': permutation}\n",
    "    \n",
    "    return randomized_data\n",
    "\n",
    "def normalizing_data(data_dict):\n",
    "    \n",
    "    flux = data_dict['FLUX']\n",
    "    labels = data_dict['LABELS']\n",
    "    wave = data_dict['WAVE']\n",
    "    redshift = data_dict['REDSHIFT']\n",
    "    \n",
    "    max_flux = []\n",
    "    normalized_flux = []\n",
    "\n",
    "    for i in range(len(flux)):\n",
    "    \n",
    "        max_flux.append(max(flux[i]))\n",
    "        \n",
    "        edited_flux = flux[i]/max_flux[i]\n",
    "    \n",
    "        normalized_flux.append(edited_flux)\n",
    "        \n",
    "    data = {'FLUX': normalized_flux, 'LABELS': labels, 'WAVE': wave, 'REDSHIFT': redshift}\n",
    "    \n",
    "    return data\n",
    "\n",
    "def creating_image_dims(data_dict):\n",
    "    \n",
    "    flux = data_dict['FLUX']\n",
    "    wave = data_dict['WAVE']\n",
    "    labels = data_dict['LABELS']\n",
    "    redshift = data_dict['REDSHIFT']\n",
    "    cut_spec = []\n",
    "    cut_wave = []\n",
    "    \n",
    "    for i in range(len(flux)): # 3.5817\n",
    "        spec = flux[i]\n",
    "        wavelength = wave[i]\n",
    "        keepidx, = np.where((wave[i] > 3.5818) & (wave[i] < 3.95))\n",
    "        cut_spec.append(spec[keepidx])\n",
    "        cut_wave.append(wavelength[keepidx])\n",
    "    \n",
    "    data = {'FLUX': cut_spec, 'LABELS': labels, 'WAVE': cut_wave, 'REDSHIFT': redshift} #'FLUX': speclen_same\n",
    "    \n",
    "    return data\n",
    "          \n",
    "\n",
    "def creating_input_tensor(samples, height , width , channels , data_dict):\n",
    "    \n",
    "    # creates input tensor of correct dimensions\n",
    "    input_tensor = np.ones((samples, height, width, channels))\n",
    "    \n",
    "    # brings in preprocessed data to input into the dimensions of the tensor\n",
    "    processed_data = creating_image_dims(normalized_data)\n",
    "    \n",
    "    # creating the list of the same length fluxs\n",
    "    fluxlen_same = processed_data['FLUX']\n",
    "    \n",
    "    # putting the length of the fluxs lists into the first axis of the tensor, while filling the 3rd axis\n",
    "    # with that specific samples flux array\n",
    "    for i in range(samples):\n",
    "        spec = fluxlen_same[i]\n",
    "        input_tensor[i,0,:,0] = spec[:]\n",
    "        \n",
    "    data = {'IMAGES': input_tensor, 'LABELS': processed_data['LABELS']}\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "def save_as_pickled_object(obj, filepath):\n",
    "    \"\"\"\n",
    "    This is a defensive way to write pickle.write, allowing for very large files on all platforms\n",
    "    \"\"\"\n",
    "    max_bytes = 2**31 - 1\n",
    "    bytes_out = pickle.dumps(obj)\n",
    "    n_bytes = sys.getsizeof(bytes_out)\n",
    "    with open(filepath, 'wb') as f_out:\n",
    "        for idx in range(0, n_bytes, max_bytes):\n",
    "            f_out.write(bytes_out[idx:idx+max_bytes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SN_dicts = reading_in_data('SN_dicts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(SN_dicts['HIGH']['WAVE'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want the maximum min and minimum max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high_SN_wave = SN_dicts['HIGH']['WAVE']\n",
    "\n",
    "# high_SN_wave = np.asarray(high_SN_wave)\n",
    "\n",
    "# print(len(high_SN_wave))\n",
    "\n",
    "# len_list = [max(high_SN_wave[i]) for i in range(len(high_SN_wave))]\n",
    "\n",
    "# a,b,c = plt.hist(len_list, bins = 500)\n",
    "# plt.grid()\n",
    "# #plt.xlim(4.01,4.018)\n",
    "# #plt.xlim(3.549,3.56)\n",
    "\n",
    "# print(min(len_list))\n",
    "# plt.title('Hist of max of wavelengths in High SN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high_SN_wave = SN_dicts['HIGH']['WAVE']\n",
    "\n",
    "# high_SN_wave = np.asarray(high_SN_wave)\n",
    "\n",
    "# print(len(high_SN_wave))\n",
    "\n",
    "# len_list = [min(high_SN_wave[i]) for i in range(len(high_SN_wave))]\n",
    "\n",
    "# a,b,c = plt.hist(len_list, bins = 500)\n",
    "# plt.grid()\n",
    "# #plt.xlim(4.01,4.018)\n",
    "# #plt.xlim(3.549,3.56)\n",
    "\n",
    "# print(max(len_list))\n",
    "# plt.title('Hist of min of wavelengths in High SN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high_SN_wave = SN_dicts['HIGH']['WAVE']\n",
    "\n",
    "# high_SN_wave = np.asarray(high_SN_wave)\n",
    "\n",
    "# print(len(high_SN_wave))\n",
    "\n",
    "# len_list = [max(high_SN_wave[i]) for i in range(len(high_SN_wave))]\n",
    "\n",
    "# a,b,c = plt.hist(len_list, bins = 500)\n",
    "# plt.grid()\n",
    "# #plt.xlim(4.01,4.018)\n",
    "# #plt.xlim(3.549,3.56)\n",
    "\n",
    "# print(min(len_list))\n",
    "# plt.title('Hist of max of wavelengths in High SN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mid_SN_wave = SN_dicts['MID']['WAVE']\n",
    "\n",
    "# mid_SN_wave = np.asarray(mid_SN_wave)\n",
    "\n",
    "# print(len(mid_SN_wave))\n",
    "\n",
    "# len_list = [min(mid_SN_wave[i]) for i in range(len(mid_SN_wave))]\n",
    "\n",
    "# a,b,c = plt.hist(len_list, bins = 500)\n",
    "# plt.grid()\n",
    "# #plt.xlim(4.01,4.018)\n",
    "# #plt.xlim(3.549,3.56)\n",
    "# print(max(len_list))\n",
    "# plt.title('Hist of min of wavelengths in Mid SN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low_SN_wave = SN_dicts['LOW']['WAVE']\n",
    "\n",
    "# low_SN_wave = np.asarray(low_SN_wave)\n",
    "\n",
    "# print(len(low_SN_wave))\n",
    "\n",
    "# len_list = [max(low_SN_wave[i]) for i in range(len(low_SN_wave))]\n",
    "\n",
    "# a,b,c = plt.hist(len_list, bins = 500)\n",
    "# plt.grid()\n",
    "# #plt.xlim(4.01,4.018)\n",
    "# #plt.xlim(3.49,3.56)\n",
    "# print(min(len_list))\n",
    "# plt.title('Hist of max of wavelengths in Low SN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low_SN_wave = SN_dicts['LOW']['WAVE']\n",
    "\n",
    "# low_SN_wave = np.asarray(low_SN_wave)\n",
    "\n",
    "# print(len(low_SN_wave))\n",
    "\n",
    "# len_list = [min(low_SN_wave[i]) for i in range(len(low_SN_wave))]\n",
    "\n",
    "# a,b,c = plt.hist(len_list, bins = 500)\n",
    "# plt.grid()\n",
    "# #plt.xlim(4.01,4.018)\n",
    "# #plt.xlim(3.49,3.56)\n",
    "# print(max(len_list))\n",
    "# plt.title('Hist of min of wavelengths in Low SN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Minimum of the low SN wavelengths =',min(low_SN_wave))\n",
    "# print('Maximum of the low SN wavelengths =',max(low_SN_wave))\n",
    "# print('Minimum of the mid SN wavelengths =',min(mid_SN_wave))\n",
    "# print('Maximum of the mid SN wavelengths =',max(mid_SN_wave))\n",
    "# print('Minimum of the high SN wavelengths =',min(high_SN_wave))\n",
    "# print('Maximum of the high SN wavelengths =',max(high_SN_wave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(low_SN_wave[0][:20])\n",
    "# print(low_SN_wave[0][-1])\n",
    "\n",
    "# print(low_SN_wave[1000][:20])\n",
    "# print(low_SN_wave[1000][:-20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mid_SN_wave[0][:20])\n",
    "# print(mid_SN_wave[1000][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(high_SN_wave[0][:20])\n",
    "# print(high_SN_wave[10000][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sifted_data_dict = sifting_data_dicts(SN_dicts,3.6234,3.9726) #3.6234, 3.9726 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# high = sifted_data_dict['HIGH']\n",
    "# mid = sifted_data_dict['MID']\n",
    "# low = sifted_data_dict['LOW']\n",
    "\n",
    "# high_wave = high['WAVE']\n",
    "# mid_wave = mid['WAVE']\n",
    "# low_wave = low['WAVE']\n",
    "\n",
    "# high_flux = high['FLUX']\n",
    "# mid_flux = mid['FLUX']\n",
    "# low_flux = low['FLUX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(high_wave[10][1000], high_flux[10][1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(high_wave[0][0])) # 4613\n",
    "# print(len(high_wave[100][100])) # 4629\n",
    "# print(len(high_wave[1000][1000])) # 4609\n",
    "# print(len(high_wave[10000][10000])) # 4603\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(mid_wave[0][0])) # 4624\n",
    "# print(len(mid_wave[100][100])) # 4614\n",
    "# print(len(mid_wave[1000][1000])) # 4612\n",
    "# print(len(mid_wave[10000][10000])) # 4621\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(low_wave[0][0])) # 4616\n",
    "# print(len(low_wave[100][100])) # 4587\n",
    "# print(len(low_wave[1000][1000])) # 4637\n",
    "# print(len(low_wave[10000][10000])) # 4582\n",
    "# print(len(low_wave[10000][30000])) # 4620"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(sifted_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high_SN_data = sifted_data_dict['HIGH']\n",
    "# # wave2 = sifted_data_dict['MID']['LABELS']\n",
    "# # wave3 = sifted_data_dict['LOW']['LABELS']\n",
    "\n",
    "\n",
    "\n",
    "# high_SN_data_labels = high_SN_data['LABELS']\n",
    "# #print(((wave1[0][:100])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(high_SN_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['QSO']\n"
     ]
    }
   ],
   "source": [
    "high_SN_data = sifted_data_dict['HIGH']\n",
    "\n",
    "print(high_SN_data['LABELS'][0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(high_labels)):\n",
    "    \n",
    "#     if high_labels[i][i] == 'QSO':\n",
    "#         high_labels[i][i] = 1\n",
    "        \n",
    "#     elif high_labels[i][i] == 'STAR':\n",
    "#         high_labels[i][i] = 0\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "SN_data = labeling_data(sifted_data_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_SN = SN_data['HIGH']\n",
    "\n",
    "high_SN_labels = high_SN['LABELS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['QSO']\n"
     ]
    }
   ],
   "source": [
    "print(high_SN_labels[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'high_SN_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b8f6841524d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhigh_SN_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhigh_SN_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'high_SN_labels' is not defined"
     ]
    }
   ],
   "source": [
    "high_SN_labels = np.asarray(high_SN_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(high_SN_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
