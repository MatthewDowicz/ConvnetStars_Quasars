{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import sys\n",
    "import pdb\n",
    "#sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_in_data(filename):\n",
    "    \n",
    "    # opens the location of the file and reads it in \n",
    "    infile = open(str(filename),'rb')\n",
    "    new_dict = pickle.load(infile)\n",
    "    infile.close()\n",
    "    \n",
    "    return new_dict\n",
    "\n",
    "def creating_SN_range_data(data_dict1):\n",
    "    \n",
    "    noise_high = []\n",
    "    flux_high = []\n",
    "    wave_high = []\n",
    "    class_high = []\n",
    "    redshift_high = []\n",
    "    \n",
    "    noise_mid = []\n",
    "    flux_mid = []\n",
    "    wave_mid = []\n",
    "    class_mid = []\n",
    "    redshift_mid = []\n",
    "    \n",
    "    noise_low = []\n",
    "    flux_low = []\n",
    "    wave_low = []\n",
    "    class_low = []\n",
    "    redshift_low = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(len(data_dict1['CLASS'])):\n",
    "        \n",
    "        if data_dict1['NOISE'][i] >= 10.:\n",
    "            \n",
    "            noise_high.append(data_dict1['NOISE'][i])\n",
    "            flux_high.append(data_dict1['FLUX'][i])\n",
    "            wave_high.append(data_dict1['WAVE'][i])\n",
    "            class_high.append(data_dict1['CLASS'][i])\n",
    "            redshift_high.append(data_dict1['REDSHIFT'][i])\n",
    "\n",
    "\n",
    "            \n",
    "        elif (data_dict1['NOISE'][i] >= 5.) & (data_dict1['NOISE'][i] <= 10.):\n",
    "            \n",
    "            noise_mid.append(data_dict1['NOISE'][i])\n",
    "            flux_mid.append(data_dict1['FLUX'][i])\n",
    "            wave_mid.append(data_dict1['WAVE'][i])\n",
    "            class_mid.append(data_dict1['CLASS'][i])\n",
    "            redshift_mid.append(data_dict1['REDSHIFT'][i])\n",
    "        \n",
    "        \n",
    "\n",
    "        elif (data_dict1['NOISE'][i] <= 5.):\n",
    "            noise_low.append(data_dict1['NOISE'][i])\n",
    "            flux_low.append(data_dict1['FLUX'][i])\n",
    "            wave_low.append(data_dict1['WAVE'][i])\n",
    "            class_low.append(data_dict1['CLASS'][i])\n",
    "            redshift_low.append(data_dict1['REDSHIFT'][i])\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    high_SN_dict = {'NOISE': noise_high, 'FLUX': flux_high, 'WAVE': wave_high,\\\n",
    "                    'CLASS': class_high, 'REDSHIFT': redshift_high}\n",
    "    \n",
    "    mid_SN_dict = {'NOISE': noise_mid, 'FLUX': flux_mid, 'WAVE': wave_mid,\\\n",
    "                    'CLASS': class_mid, 'REDSHIFT': redshift_mid}\n",
    "    \n",
    "    low_SN_dict = {'NOISE': noise_low, 'FLUX': flux_low, 'WAVE': wave_low,\\\n",
    "                    'CLASS': class_low, 'REDSHIFT': redshift_low}\n",
    "    \n",
    "    SN_dict = {'HIGH': high_SN_dict, 'MID': mid_SN_dict, 'LOW': low_SN_dict}\n",
    "    \n",
    "    return SN_dict\n",
    "\n",
    "\n",
    "\n",
    "def SN_data_selection(data_dict1, data_dict2):\n",
    "    \n",
    "    dict1 = creating_SN_range_data(data_dict1)\n",
    "    dict2 = creating_SN_range_data(data_dict2)\n",
    "    \n",
    "    high_SN1 = dict1['HIGH']\n",
    "    mid_SN1 = dict1['MID']\n",
    "    low_SN1 = dict1['LOW']\n",
    "    \n",
    "    high_SN2 = dict2['HIGH']\n",
    "    mid_SN2 = dict2['MID']\n",
    "    low_SN2 = dict2['LOW']\n",
    "    \n",
    "\n",
    "    \n",
    "    if (len(high_SN1['CLASS'])) > (len(high_SN2['CLASS'])):\n",
    "        \n",
    "        cut_high_SN1_class = high_SN1['CLASS'][:len(high_SN2['CLASS'])]\n",
    "        cut_high_SN1_wave = high_SN1['WAVE'][:len(high_SN2['WAVE'])]\n",
    "        cut_high_SN1_flux = high_SN1['FLUX'][:len(high_SN2['FLUX'])]\n",
    "        cut_high_SN1_noise = high_SN1['NOISE'][:len(high_SN2['NOISE'])]\n",
    "        cut_high_SN1_redshift = high_SN1['REDSHIFT'][:len(high_SN2['REDSHIFT'])]\n",
    "        \n",
    "        cut_high_SN2_class = high_SN2['CLASS']\n",
    "        cut_high_SN2_wave = high_SN2['WAVE']\n",
    "        cut_high_SN2_flux = high_SN2['FLUX']\n",
    "        cut_high_SN2_noise = high_SN2['NOISE']\n",
    "        cut_high_SN2_redshift = high_SN2['REDSHIFT']\n",
    "        \n",
    "        \n",
    "    elif (len(high_SN1['CLASS'])) < (len(high_SN2['CLASS'])): \n",
    "        \n",
    "        cut_high_SN1_class = high_SN1['CLASS']\n",
    "        cut_high_SN1_wave = high_SN1['WAVE']\n",
    "        cut_high_SN1_flux = high_SN1['FLUX']\n",
    "        cut_high_SN1_noise = high_SN1['NOISE']\n",
    "        cut_high_SN1_redshift = high_SN1['REDSHIFT']\n",
    "        \n",
    "        cut_high_SN2_class = high_SN2['CLASS'][:len(high_SN1['CLASS'])]\n",
    "        cut_high_SN2_wave = high_SN2['WAVE'][:len(high_SN1['WAVE'])]\n",
    "        cut_high_SN2_flux = high_SN2['FLUX'][:len(high_SN1['FLUX'])]\n",
    "        cut_high_SN2_noise = high_SN2['NOISE'][:len(high_SN1['NOISE'])]\n",
    "        cut_high_SN2_redshift = high_SN2['REDSHIFT'][:len(high_SN1['REDSHIFT'])]\n",
    "        \n",
    "    if (len(mid_SN1['CLASS'])) > (len(mid_SN2['CLASS'])):\n",
    "        \n",
    "        cut_mid_SN1_class = mid_SN1['CLASS'][:len(mid_SN2['CLASS'])]\n",
    "        cut_mid_SN1_wave = mid_SN1['WAVE'][:len(mid_SN2['WAVE'])]\n",
    "        cut_mid_SN1_flux = mid_SN1['FLUX'][:len(mid_SN2['FLUX'])]\n",
    "        cut_mid_SN1_noise = mid_SN1['NOISE'][:len(mid_SN2['NOISE'])]\n",
    "        cut_mid_SN1_redshift = mid_SN1['REDSHIFT'][:len(mid_SN2['REDSHIFT'])]\n",
    "        \n",
    "        cut_mid_SN2_class = mid_SN2['CLASS']\n",
    "        cut_mid_SN2_wave = mid_SN2['WAVE']\n",
    "        cut_mid_SN2_flux = mid_SN2['FLUX']\n",
    "        cut_mid_SN2_noise = mid_SN2['NOISE']\n",
    "        cut_mid_SN2_redshift = mid_SN2['REDSHIFT']\n",
    "        \n",
    "        \n",
    "    elif (len(mid_SN1['CLASS'])) < (len(mid_SN2['CLASS'])): \n",
    "        \n",
    "        cut_mid_SN1_class = mid_SN1['CLASS']\n",
    "        cut_mid_SN1_wave = mid_SN1['WAVE']\n",
    "        cut_mid_SN1_flux = mid_SN1['FLUX']\n",
    "        cut_mid_SN1_noise = mid_SN1['NOISE']\n",
    "        cut_mid_SN1_redshift = mid_SN1['REDSHIFT']\n",
    "        \n",
    "        cut_mid_SN2_class = mid_SN2['CLASS'][:len(mid_SN1['CLASS'])]\n",
    "        cut_mid_SN2_wave = mid_SN2['WAVE'][:len(mid_SN1['WAVE'])]\n",
    "        cut_mid_SN2_flux = mid_SN2['FLUX'][:len(mid_SN1['FLUX'])]\n",
    "        cut_mid_SN2_noise = mid_SN2['NOISE'][:len(mid_SN1['NOISE'])]\n",
    "        cut_mid_SN2_redshift = mid_SN2['REDSHIFT'][:len(mid_SN1['REDSHIFT'])]\n",
    "        \n",
    "        \n",
    "    if (len(low_SN1['CLASS'])) > (len(low_SN2['CLASS'])):\n",
    "        \n",
    "        cut_low_SN1_class = low_SN1['CLASS'][:len(low_SN2['CLASS'])]\n",
    "        cut_low_SN1_wave = low_SN1['WAVE'][:len(low_SN2['WAVE'])]\n",
    "        cut_low_SN1_flux = low_SN1['FLUX'][:len(low_SN2['FLUX'])]\n",
    "        cut_low_SN1_noise = low_SN1['NOISE'][:len(low_SN2['NOISE'])]\n",
    "        cut_low_SN1_redshift = low_SN1['REDSHIFT'][:len(low_SN2['REDSHIFT'])]\n",
    "        \n",
    "        cut_low_SN2_class = low_SN2['CLASS']\n",
    "        cut_low_SN2_wave = low_SN2['WAVE']\n",
    "        cut_low_SN2_flux = low_SN2['FLUX']\n",
    "        cut_low_SN2_noise = low_SN2['NOISE']\n",
    "        cut_low_SN2_redshift = low_SN2['REDSHIFT']\n",
    "        \n",
    "        \n",
    "    elif (len(low_SN1['CLASS'])) < (len(low_SN2['CLASS'])): \n",
    "        \n",
    "        cut_low_SN1_class = low_SN1['CLASS']\n",
    "        cut_low_SN1_wave = low_SN1['WAVE']\n",
    "        cut_low_SN1_flux = low_SN1['FLUX']\n",
    "        cut_low_SN1_noise = low_SN1['NOISE']\n",
    "        cut_low_SN1_redshift = low_SN1['REDSHIFT']\n",
    "        \n",
    "        cut_low_SN2_class = low_SN2['CLASS'][:len(low_SN1['CLASS'])]\n",
    "        cut_low_SN2_wave = low_SN2['WAVE'][:len(low_SN1['WAVE'])]\n",
    "        cut_low_SN2_flux = low_SN2['FLUX'][:len(low_SN1['FLUX'])]\n",
    "        cut_low_SN2_noise = low_SN2['NOISE'][:len(low_SN1['NOISE'])]\n",
    "        cut_low_SN2_redshift = low_SN2['REDSHIFT'][:len(low_SN1['REDSHIFT'])]\n",
    "        \n",
    "        \n",
    "        \n",
    "    high_SN_class = cut_high_SN1_class + cut_high_SN2_class\n",
    "    high_SN_wave = cut_high_SN1_wave + cut_high_SN2_wave\n",
    "    high_SN_flux = cut_high_SN1_flux + cut_high_SN2_flux\n",
    "    high_SN_noise = cut_high_SN1_noise + cut_high_SN2_noise\n",
    "    high_SN_redshift = cut_high_SN1_redshift + cut_high_SN2_redshift\n",
    "    \n",
    "    \n",
    "    mid_SN_class = cut_mid_SN1_class + cut_mid_SN2_class\n",
    "    mid_SN_wave = cut_mid_SN1_wave + cut_mid_SN2_wave\n",
    "    mid_SN_flux = cut_mid_SN1_flux + cut_mid_SN2_flux\n",
    "    mid_SN_noise = cut_mid_SN1_noise + cut_mid_SN2_noise\n",
    "    mid_SN_redshift = cut_mid_SN1_redshift + cut_mid_SN2_redshift\n",
    "        \n",
    "    \n",
    "    low_SN_class = cut_low_SN1_class + cut_low_SN2_class\n",
    "    low_SN_wave = cut_low_SN1_wave + cut_low_SN2_wave\n",
    "    low_SN_flux = cut_low_SN1_flux + cut_low_SN2_flux\n",
    "    low_SN_noise = cut_low_SN1_noise + cut_low_SN2_noise\n",
    "    low_SN_redshift = cut_low_SN1_redshift + cut_low_SN2_redshift\n",
    "        \n",
    "        \n",
    "    high_SN_dict = {'CLASS': high_SN_class, 'WAVE': high_SN_wave, 'FLUX': high_SN_flux,\\\n",
    "                   'NOISE': high_SN_noise, 'REDSHIFT': high_SN_redshift}\n",
    "    \n",
    "    mid_SN_dict = {'CLASS': mid_SN_class, 'WAVE': mid_SN_wave, 'FLUX': mid_SN_flux,\\\n",
    "                   'NOISE': mid_SN_noise, 'REDSHIFT': mid_SN_redshift}\n",
    "    \n",
    "    low_SN_dict = {'CLASS': low_SN_class, 'WAVE': low_SN_wave, 'FLUX': low_SN_flux,\\\n",
    "                   'NOISE': low_SN_noise, 'REDSHIFT': low_SN_redshift}\n",
    "\n",
    "    SN_dicts = {'HIGH': high_SN_dict, 'MID': mid_SN_dict, 'LOW': low_SN_dict}\n",
    "    \n",
    "    return SN_dicts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_as_pickled_object(obj, filepath):\n",
    "    \"\"\"\n",
    "    This is a defensive way to write pickle.write, allowing for very large files on all platforms\n",
    "    \"\"\"\n",
    "    max_bytes = 2**31 - 1\n",
    "    bytes_out = pickle.dumps(obj)\n",
    "    n_bytes = sys.getsizeof(bytes_out)\n",
    "    with open(filepath, 'wb') as f_out:\n",
    "        for idx in range(0, n_bytes, max_bytes):\n",
    "            f_out.write(bytes_out[idx:idx+max_bytes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "quasar_dict = reading_in_data('quasar_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['FLUX', 'CLASS', 'NOISE', 'WAVE', 'REDSHIFT', 'PLATE', 'MJD', 'FIBER', 'PSFMAG', 'R', 'G'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quasar_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_dict = reading_in_data('star_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['FLUX', 'CLASS', 'NOISE', 'WAVE', 'REDSHIFT', 'PLATE', 'MJD', 'FIBER', 'PSFMAG', 'R', 'G'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "star_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create high SN cut-off at >10 (High). Train on that and test on two different sets of low SN 1) 5-10(mid) & 2) <= 5 (low)\n",
    "\n",
    "Train the CNN on just high SN and test on Low\n",
    "\n",
    "Train CNN on mixture of high/low SN and test on the same Low set \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SN_dicts = SN_data_selection(star_dict, quasar_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_pickled_object(SN_dicts, \"SN_dicts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('High length =',len(SN_dicts['HIGH']['CLASS']))\n",
    "# print('Mid length =',len(SN_dicts['MID']['CLASS']))\n",
    "# print('Low length =',len(SN_dicts['LOW']['CLASS']))\n",
    "\n",
    "\n",
    "# high_SN_dict = SN_dicts['HIGH']\n",
    "\n",
    "# mid_SN_dict = SN_dicts['MID']\n",
    "# low_SN_dict = SN_dicts['LOW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stars = []\n",
    "# quasars = []\n",
    "\n",
    "# stars1 = []\n",
    "# quasars1 = []\n",
    "\n",
    "# for i in range(len(high_SN_dict['CLASS'])):\n",
    "    \n",
    "#     if high_SN_dict['CLASS'][i] == \"QSO\":\n",
    "    \n",
    "#         quasars.append(high_SN_dict['CLASS'][i])\n",
    "#         quasars1.append(high_SN_dict['NOISE'][i])\n",
    "        \n",
    "#     elif high_SN_dict['CLASS'][i] == 'STAR':\n",
    "#         stars.append(high_SN_dict['CLASS'][i])\n",
    "#         stars1.append(high_SN_dict['NOISE'][i])\n",
    "    \n",
    "    \n",
    "# for i in range(len(mid_SN_dict['CLASS'])):\n",
    "    \n",
    "#     if mid_SN_dict['CLASS'][i] == \"QSO\":\n",
    "    \n",
    "#         quasars.append(mid_SN_dict['CLASS'][i])\n",
    "#         quasars1.append(mid_SN_dict['NOISE'][i])\n",
    "        \n",
    "#     elif mid_SN_dict['CLASS'][i] == 'STAR':\n",
    "#         stars.append(mid_SN_dict['CLASS'][i])\n",
    "#         stars1.append(mid_SN_dict['NOISE'][i])\n",
    "    \n",
    "# for i in range(len(low_SN_dict['CLASS'])):\n",
    "    \n",
    "#     if low_SN_dict['CLASS'][i] == \"QSO\":\n",
    "    \n",
    "#         quasars.append(low_SN_dict['CLASS'][i])\n",
    "#         quasars1.append(low_SN_dict['NOISE'][i])\n",
    "        \n",
    "#     elif low_SN_dict['CLASS'][i] == 'STAR':\n",
    "#         stars.append(low_SN_dict['CLASS'][i])\n",
    "#         stars1.append(low_SN_dict['NOISE'][i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
