{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import time\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyfiles_fromfolder_tofolder(Root_dir,target_folder,extension):\n",
    "    RootDir1 = str(Root_dir)\n",
    "    TargetFolder = str(target_folder)\n",
    "    for root, dirs, files in os.walk((os.path.normpath(RootDir1)), topdown=False):\n",
    "        for name in files:\n",
    "            if name.endswith(str(extension)):\n",
    "                SourceFolder = os.path.join(root,name)\n",
    "                shutil.copy2(SourceFolder, TargetFolder)\n",
    "                \n",
    "def get_filenames(path='.', extension=None, pattern=None, identifiers=None, include_path=False):\n",
    "   \n",
    "    # retrieve all filenames from the directory\n",
    "    filename_list = os.listdir(path)\n",
    "    \n",
    "    # keep all filenames with the proper extension\n",
    "    if extension is not None:\n",
    "        \n",
    "        filename_list = [filename for filename in filename_list if\n",
    "                         filename[-len(extension):] == extension]\n",
    "        \n",
    "    # keep all filenames that match the pattern\n",
    "    if pattern is not None:\n",
    "        filename_list = [filename for filename in filename_list if re.search(pattern, filename)]\n",
    "        \n",
    "    # keep all filenames that match the identifiers provided\n",
    "    if identifiers is not None:\n",
    "        storage_list = []\n",
    "        \n",
    "        try:\n",
    "            for ident in identifiers:\n",
    "                storage_list.extend([filename for filename in filename_list if str(ident) in filename])\n",
    "                \n",
    "        except TypeError:\n",
    "            print(identifiers, 'is not a list, tuple, or otherwise iterable')\n",
    "            \n",
    "        else:\n",
    "            filename_list = storage_list\n",
    "            \n",
    "    if include_path:\n",
    "        filename_list = [path + filename for filename in filename_list]\n",
    "        \n",
    "    return filename_list\n",
    "\n",
    "\n",
    "def get_filevalues(path, filename_list): \n",
    "    \n",
    "    list_fluxarrays = []\n",
    "    list_classtype = []\n",
    "    list_noise = []\n",
    "    list_wavelength = []\n",
    "    list_redshift = []\n",
    "    \n",
    "    \n",
    "    for i in range(len(filename_list)):\n",
    "        with fits.open(str(path) +str(filename_list[i])+ \"\", memmap = False ) as hdul:\n",
    "            \n",
    "            data_c = hdul['COADD'].data\n",
    "            data_s = hdul['SPALL'].data\n",
    "            \n",
    "            flux_val = data_c.field(\"flux\")\n",
    "            list_fluxarrays.append(flux_val) \n",
    "            \n",
    "            classtype = data_s.field('CLASS')\n",
    "            list_classtype.append(classtype)\n",
    "            \n",
    "            noise_val = data_s.field('SN_MEDIAN_ALL')\n",
    "            list_noise.append(noise_val)\n",
    "            \n",
    "            wavelength_val = data_c.field('loglam')\n",
    "            list_wavelength.append(wavelength_val)\n",
    "            \n",
    "            redshift_val = data_s.field('Z')\n",
    "            list_redshift.append(redshift_val)\n",
    "            \n",
    "            values = {'FLUX': list_fluxarrays, 'CLASS': list_classtype, 'NOISE': list_noise,\\\n",
    "                      'WAVE': list_wavelength, 'REDSHIFT': list_redshift}\n",
    "            \n",
    "            hdul.close()\n",
    "            del hdul['COADD'].data\n",
    "            del hdul['PRIMARY'].data\n",
    "            del hdul['SPALL'].data\n",
    "            del hdul\n",
    "            \n",
    "    return values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/matt/Desktop/DESI_Research/DESI_ML/good_stars/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-021bd8aa8935>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstardata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_filenames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/matt/Desktop/DESI_Research/DESI_ML/good_stars/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.fits'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-9af82957adb6>\u001b[0m in \u001b[0;36mget_filenames\u001b[0;34m(path, extension, pattern, identifiers, include_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# retrieve all filenames from the directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mfilename_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# keep all filenames with the proper extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/matt/Desktop/DESI_Research/DESI_ML/good_stars/'"
     ]
    }
   ],
   "source": [
    "stardata = get_filenames(\"/Users/matt/Desktop/DESI_Research/DESI_ML/good_stars/\", '.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_dict = get_filevalues(\"/Users/matt/Desktop/DESI_Research/DESI_ML/good_stars/\", stardata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_flux = star_dict['FLUX']\n",
    "star_labels = star_dict['CLASS'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of the lengths of the flux arrays\n",
    "star_fluxlen_list = [len(star_flux[i]) for i in range(len(star_flux))]\n",
    "\n",
    "# create list of all the flux lengths that are greater than 4550\n",
    "cut_star_fluxlen_list = [i for i in star_fluxlen_list if i >= 4550]\n",
    "\n",
    "# creates array of the star fluxs that have a length greater than 4550\n",
    "filtered_star_flux_list = np.array(star_flux)[np.array(cut_star_fluxlen_list)]\n",
    "print(len(filtered_star_flux_list))\n",
    "\n",
    "# creates array of the star labels that correspond to \n",
    "filtered_star_labels_list = np.array(star_labels)[np.array(cut_star_fluxlen_list)]\n",
    "print(len(filtered_star_labels_list))\n",
    "\n",
    "# creates array of star fluxs that have all the same length ie len of 4550\n",
    "star_fluxlen_same = [filtered_star_flux_list[i][:4550] for i in range(len(filtered_star_flux_list))]\n",
    "starflux_same = star_fluxlen_same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "star_tensor = np.ones((5013,1,4550,1))\n",
    "\n",
    "for i in range(5013):\n",
    "    spec = starflux_same[i]\n",
    "    star_tensor[i,0,:,0] = spec[:]\n",
    "    \n",
    "print(np.shape(star_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print((filtered_star_flux_list[0][100:110])) # why is the rounding different between these two?\n",
    "print((star_tensor[0,0,100:110,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_train_images = star_tensor[:3013, :, :, :]\n",
    "star_train_labels = np.ones(3013)\n",
    "\n",
    "star_val_images = star_tensor[3013:4013, :, :, :]\n",
    "star_val_labels = np.ones(1000,)\n",
    "\n",
    "star_test_images = star_tensor[4013:, :, :, :]\n",
    "star_test_labels = np.ones(1000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(star_train_images))\n",
    "print(np.shape(star_train_labels))\n",
    "\n",
    "print(np.shape(star_val_images))\n",
    "print(np.shape(star_val_labels))\n",
    "\n",
    "print(np.shape(star_test_images))\n",
    "print(np.shape(star_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()                                      #input_shape = (height, width, channels)\n",
    "model.add(keras.layers.Conv2D(64, (1,32) ,activation='relu',input_shape=(1,4550,1),padding='same',\\\n",
    "                              data_format='channels_last'))\n",
    "model.add(keras.layers.MaxPooling2D((1,7), strides=(1,4)))\n",
    "model.add(keras.layers.Conv2D(72, (1,16),activation='relu',padding = 'same'))\n",
    "model.add(keras.layers.MaxPooling2D((1,7), strides=(1,4)))\n",
    "model.add(keras.layers.Flatten())\n",
    "#potentially add dropout here at value = 0.5\n",
    "model.add(keras.layers.Dense(units = 16, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(star_train_images,\n",
    "star_train_labels,\n",
    "epochs=10,\n",
    "batch_size= 64,\n",
    "validation_data=(star_val_images, star_val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(star_test_images, star_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
