{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import keras\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(path='.', extension=None, pattern=None, identifiers=None, include_path=False):\n",
    "   \n",
    "    # retrieve all filenames from the directory\n",
    "    filename_list = os.listdir(path)\n",
    "    \n",
    "    # keep all filenames with the proper extension\n",
    "    if extension is not None:\n",
    "        \n",
    "        filename_list = [filename for filename in filename_list if\n",
    "                         filename[-len(extension):] == extension]\n",
    "        \n",
    "    # keep all filenames that match the pattern\n",
    "    if pattern is not None:\n",
    "        filename_list = [filename for filename in filename_list if re.search(pattern, filename)]\n",
    "        \n",
    "    # keep all filenames that match the identifiers provided\n",
    "    if identifiers is not None:\n",
    "        storage_list = []\n",
    "        \n",
    "        try:\n",
    "            for ident in identifiers:\n",
    "                storage_list.extend([filename for filename in filename_list if str(ident) in filename])\n",
    "                \n",
    "        except TypeError:\n",
    "            print(identifiers, 'is not a list, tuple, or otherwise iterable')\n",
    "            \n",
    "        else:\n",
    "            filename_list = storage_list\n",
    "            \n",
    "    if include_path:\n",
    "        filename_list = [path + filename for filename in filename_list]\n",
    "        \n",
    "    return filename_list\n",
    "\n",
    "\n",
    "def get_filevalues(path, filename_list): \n",
    "    \n",
    "    # empty lists \n",
    "    list_fluxarrays = []\n",
    "    list_classtype = []\n",
    "    list_noise = []\n",
    "    list_wavelength = []\n",
    "    list_redshift = []\n",
    "    \n",
    "    # going through all the fits files\n",
    "    for i in range(len(filename_list)):\n",
    "        with fits.open(str(path) +str(filename_list[i])+ \"\", memmap = False ) as hdul:\n",
    "            \n",
    "            data_c = hdul['COADD'].data \n",
    "           \n",
    "            # the 2nd HDU is different in certain quasars\n",
    "            # this is appending all the ones with \"SPALL\" as the their 2nd HDU\n",
    "            if hdul[2].name == \"SPALL\":\n",
    "                \n",
    "                data_s = hdul['SPALL'].data\n",
    "                \n",
    "                flux_val = data_c.field(\"flux\")\n",
    "                list_fluxarrays.append(flux_val) \n",
    "            \n",
    "                classtype = data_s.field('CLASS')\n",
    "                list_classtype.append(classtype)\n",
    "            \n",
    "                noise_val = data_s.field('SN_MEDIAN_ALL')\n",
    "                list_noise.append(noise_val)\n",
    "            \n",
    "                wavelength_val = data_c.field('loglam')\n",
    "                list_wavelength.append(wavelength_val)\n",
    "            \n",
    "                redshift_val = data_s.field('Z')\n",
    "                list_redshift.append(redshift_val)\n",
    "                \n",
    "                del hdul['SPALL'].data\n",
    "            \n",
    "            # this is appending all the values for the quasars with \"SPECOBJ\" as their 2nd HDU\n",
    "            elif hdul[2].name == \"SPECOBJ\":\n",
    "                \n",
    "                data_s = hdul['SPECOBJ'].data\n",
    "                \n",
    "                flux_val = data_c.field(\"flux\")\n",
    "                list_fluxarrays.append(flux_val) \n",
    "            \n",
    "                classtype = data_s.field('CLASS')\n",
    "                list_classtype.append(classtype)\n",
    "            \n",
    "                noise_val = data_s.field('SN_MEDIAN_ALL')\n",
    "                list_noise.append(noise_val)\n",
    "            \n",
    "                wavelength_val = data_c.field('loglam')\n",
    "                list_wavelength.append(wavelength_val)\n",
    "            \n",
    "                redshift_val = data_s.field('Z')\n",
    "                list_redshift.append(redshift_val)\n",
    "                \n",
    "                del hdul['SPECOBJ'].data\n",
    "            \n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            \n",
    "            values = {'FLUX': list_fluxarrays, 'CLASS': list_classtype, 'NOISE': list_noise,\\\n",
    "                      'WAVE': list_wavelength, 'REDSHIFT': list_redshift }\n",
    "            \n",
    "            hdul.close()\n",
    "            del hdul['COADD'].data\n",
    "            del hdul['PRIMARY'].data\n",
    "            del hdul\n",
    "            \n",
    "    return values    \n",
    "\n",
    "def save_data_to_disk(name_file, saved_variable):\n",
    "    \n",
    "    filename = str(name_file)\n",
    "    outfile = open(filename,'wb')\n",
    "    \n",
    "    pickle.dump(saved_variable,outfile)\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "quasardata = get_filenames(\"/Users/matt/Desktop/DESI_Research/DESI_ML/Quasars_data/\", extension='.fits')\n",
    "quasar_dict = get_filevalues(\"/Users/matt/Desktop/DESI_Research/DESI_ML/Quasars_data/\", quasardata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stardata = get_filenames(\"/Users/matt/Desktop/DESI_Research/DESI_ML/Stars_data/\", '.fits')\n",
    "star_dict = get_filevalues(\"/Users/matt/Desktop/DESI_Research/DESI_ML/Stars_data/\", stardata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = (star_dict['REDSHIFT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1158\n"
     ]
    }
   ],
   "source": [
    "new_z = []\n",
    "    \n",
    "for i in range(len(z)):\n",
    "    if (z[i] >= 2) & (z[i] <= 3.0):\n",
    "        new_z.append(z[i])\n",
    "print(len(new_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'quasar_data'\n",
    "outfile = open(filename,'wb')\n",
    "\n",
    "pickle.dump(quasar_dict,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open(filename,'rb')\n",
    "new_dict = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(quasar_dict)\n",
    "#print(new_dict==quasar_dict)\n",
    "print(type(new_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(quasar_dict['FLUX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_dict['FLUX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'star_data'\n",
    "outfile = open(filename,'wb')\n",
    "\n",
    "pickle.dump(star_dict,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
